#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

name: CI

on:
  push:
    branches:
      - master
      - branch-*
  pull_request:
    branches:
      - master
      - branch-*

concurrency:
  group: test-${{ github.ref }}
  cancel-in-progress: true

jobs:

  spark-on-k8s-it:
    name: Spark Engine On Kubernetes Integration Test
    runs-on: ubuntu-20.04
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      # from https://github.com/marketplace/actions/setup-minikube-kubernetes-cluster
      - name: Setup Minikube
        uses: manusa/actions-setup-minikube@v2.4.3
        with:
          minikube version: 'v1.25.2'
          kubernetes version: 'v1.23.3'
          driver: docker
          start args: '--extra-config=kubeadm.ignore-preflight-errors=NumCPU --force --cpus 2 --memory 4096'
      # in case: https://spark.apache.org/docs/latest/running-on-kubernetes.html#rbac
      - name: Create Service Account
        run: |
          kubectl create serviceaccount spark
          kubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=default:spark --namespace=default
          kubectl get serviceaccount
      - name: integration tests
        run: >-
          ./build/mvn clean install
          -Dmaven.javadoc.skip=true
          -Drat.skip=true
          -Dscalastyle.skip=true
          -Dspotless.check.skip
          -Dspark.version=3.2.1
          -Pflink-provided,hive-provided
          -Pkubernetes-it
          -Dtest=none -DwildcardSuites=org.apache.kyuubi.kubernetes.test.spark
      - name: Print Driver Pod logs
        if: failure()
        run: kubectl get pods | grep driver | awk -F " " '{print$1}' | xargs -I {} kubectl logs {}
      - name: Upload test logs
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: unit-tests-log
          path: |
            **/target/unit-tests.log
            **/kyuubi-spark-sql-engine.log*
